{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96553c7f",
   "metadata": {},
   "source": [
    "# Homework Reflections Week 9 - Week 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac6f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import statsmodels.formula.api as smf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85341d17",
   "metadata": {},
   "source": [
    "# Week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae264b86",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0928a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053725 empirical std of slope\n",
      "0.03155 mean OLS-reported standard error\n"
     ]
    }
   ],
   "source": [
    "def simulate_se(true_effect=1, var_x=1, sample_size=1000, n_sims=1000, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    slope_list = []\n",
    "    ols_se_list = []\n",
    "\n",
    "    for _ in range(n_sims):\n",
    "        x = np.random.normal(0, np.sqrt(var_x), sample_size)\n",
    "        eps = np.random.normal(0, np.abs(x), sample_size)\n",
    "        y = true_effect * x + eps\n",
    "\n",
    "        X = sm.add_constant(x)\n",
    "        fit = sm.OLS(y, X).fit()\n",
    "        slope_list.append(fit.params[1])\n",
    "        ols_se_list.append(fit.bse[1])\n",
    "\n",
    "    empirical_std = float(np.std(slope_list))\n",
    "    mean_ols_se = float(np.mean(ols_se_list))\n",
    "\n",
    "    print(round(empirical_std, 6), \"empirical std of slope\")\n",
    "    print(round(mean_ols_se, 6), \"mean OLS-reported standard error\")\n",
    "\n",
    "simulate_se()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ffb8f0",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1be4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho = 0\n",
      "True SD: 0.034961095241031345\n",
      "OLS SE: 0.034365599495386354\n",
      "Bootstrap SE: 0.03397123700874447\n",
      "\n",
      "rho = 0.5\n",
      "True SD: 0.05480789361052515\n",
      "OLS SE: 0.0335361108459322\n",
      "Bootstrap SE: 0.03282796958384208\n",
      "\n",
      "rho = 0.9\n",
      "True SD: 0.11967134331095981\n",
      "OLS SE: 0.02809543976701594\n",
      "Bootstrap SE: 0.02756967309808162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def make_data(n, rho):\n",
    "    x = np.linspace(0, 10, n)\n",
    "    # create correlated errors\n",
    "    cov = rho ** np.abs(np.subtract.outer(np.arange(n), np.arange(n)))\n",
    "    e = np.random.multivariate_normal(np.zeros(n), cov)\n",
    "    y = 2 * x + e\n",
    "    return x, y\n",
    "\n",
    "def run_sim(n=100, rho=0.9, sims=200, boots=100):\n",
    "    slopes = []\n",
    "    ols_se = []\n",
    "    boot_se = []\n",
    "\n",
    "    for _ in range(sims):\n",
    "        x, y = make_data(n, rho)\n",
    "        X = sm.add_constant(x)\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        slopes.append(model.params[1])\n",
    "        ols_se.append(model.bse[1])\n",
    "\n",
    "        # bootstrap residuals\n",
    "        boot_slopes = []\n",
    "        for _ in range(boots):\n",
    "            r = resample(model.resid)\n",
    "            yb = model.fittedvalues + r\n",
    "            b_model = sm.OLS(yb, X).fit()\n",
    "            boot_slopes.append(b_model.params[1])\n",
    "        boot_se.append(np.std(boot_slopes))\n",
    "\n",
    "    print(\"rho =\", rho)\n",
    "    print(\"True SD:\", np.std(slopes))\n",
    "    print(\"OLS SE:\", np.mean(ols_se))\n",
    "    print(\"Bootstrap SE:\", np.mean(boot_se))\n",
    "    print()\n",
    "\n",
    "for rho in [0, 0.5, 0.9]:\n",
    "    run_sim(rho=rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbbe19",
   "metadata": {},
   "source": [
    "# Week 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3853b",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeaa6557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A: Value Only\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        76\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n",
      "Model B: Value + Derivative + Second Derivative\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        76\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make reproducible data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create time axis\n",
    "time_points = np.linspace(0, 20, 500)\n",
    "\n",
    "# Event happens at t = 10\n",
    "event_time = 10\n",
    "\n",
    "# Make a baseline trend\n",
    "# Before event: smooth curve\n",
    "baseline_value = 0.2 * time_points + 2 * np.sin(time_points * 0.3)\n",
    "\n",
    "# Create jumps at event\n",
    "jump_value = 5\n",
    "jump_derivative = 2\n",
    "jump_second_derivative = 1.2\n",
    "\n",
    "# Build synthetic \"value\" after event\n",
    "value_after_event = baseline_value + jump_value * (time_points >= event_time)\n",
    "\n",
    "# Build synthetic derivative: simple numerical derivative\n",
    "value_derivative = np.gradient(value_after_event)\n",
    "\n",
    "# Add jump to derivative\n",
    "value_derivative = value_derivative + jump_derivative * (time_points >= event_time)\n",
    "\n",
    "# Build synthetic second derivative\n",
    "value_second_derivative = np.gradient(value_derivative)\n",
    "\n",
    "# Add jump to second derivative\n",
    "value_second_derivative = value_second_derivative + jump_second_derivative * (time_points >= event_time)\n",
    "\n",
    "# Add noise to make it realistic\n",
    "value_after_event = value_after_event + np.random.normal(0, 0.3, len(time_points))\n",
    "value_derivative = value_derivative + np.random.normal(0, 0.2, len(time_points))\n",
    "value_second_derivative = value_second_derivative + np.random.normal(0, 0.2, len(time_points))\n",
    "\n",
    "# Build labels: 1 if event has passed, 0 otherwise\n",
    "labels = (time_points >= event_time).astype(int)\n",
    "\n",
    "# Put features into arrays\n",
    "features_value_only = np.column_stack([value_after_event])\n",
    "features_all_three = np.column_stack([\n",
    "    value_after_event,\n",
    "    value_derivative,\n",
    "    value_second_derivative\n",
    "])\n",
    "\n",
    "# Split into train and test\n",
    "train_value, test_value, train_labels, test_labels = train_test_split(\n",
    "    features_value_only, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "train_three, test_three, train_labels_2, test_labels_2 = train_test_split(\n",
    "    features_all_three, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train models\n",
    "model_value_only = LogisticRegression()\n",
    "model_value_only.fit(train_value, train_labels)\n",
    "\n",
    "model_three = LogisticRegression()\n",
    "model_three.fit(train_three, train_labels_2)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Model A: Value Only\")\n",
    "print(classification_report(test_labels, model_value_only.predict(test_value)))\n",
    "\n",
    "print(\"Model B: Value + Derivative + Second Derivative\")\n",
    "print(classification_report(test_labels_2, model_three.predict(test_three)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92748d27",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b0a899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.963\n",
      "Model:                            OLS   Adj. R-squared:                  0.962\n",
      "Method:                 Least Squares   F-statistic:                     1004.\n",
      "Date:                Thu, 20 Nov 2025   Prob (F-statistic):           8.59e-83\n",
      "Time:                        11:52:18   Log-Likelihood:                -275.13\n",
      "No. Observations:                 120   AIC:                             558.3\n",
      "Df Residuals:                     116   BIC:                             569.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         8.5866      0.445     19.299      0.000       7.705       9.468\n",
      "C(group)[T.B]    10.1896      0.545     18.699      0.000       9.110      11.269\n",
      "C(group)[T.C]    20.2288      0.545     37.123      0.000      19.150      21.308\n",
      "post_event       17.9896      0.445     40.433      0.000      17.108      18.871\n",
      "==============================================================================\n",
      "Omnibus:                       14.589   Durbin-Watson:                   0.684\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                4.573\n",
      "Skew:                          -0.030   Prob(JB):                        0.102\n",
      "Kurtosis:                       2.046   Cond. No.                         4.22\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create time axis\n",
    "time_points = np.arange(0, 40)\n",
    "\n",
    "# Three groups\n",
    "groups = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "# Different starting values\n",
    "baseline_levels = {\"A\": 5, \"B\": 15, \"C\": 25}\n",
    "\n",
    "# Common trend slope\n",
    "trend_slope = 0.4\n",
    "\n",
    "# Event happens here\n",
    "event_time = 20\n",
    "jump_amount = 10\n",
    "\n",
    "# Make dataset\n",
    "rows = []\n",
    "for group in groups:\n",
    "    for t in time_points:\n",
    "        baseline_value = baseline_levels[group]\n",
    "        trend_value = baseline_value + trend_slope * t\n",
    "        jump_value = jump_amount if t >= event_time else 0\n",
    "        noisy_value = trend_value + jump_value + np.random.normal(0, 1)\n",
    "        rows.append([group, t, noisy_value, int(t >= event_time)])\n",
    "\n",
    "data = pd.DataFrame(rows, columns=[\"group\", \"time\", \"value\", \"post_event\"])\n",
    "\n",
    "# Fit model with group fixed effects and event effect\n",
    "model = smf.ols(\"value ~ post_event + C(group)\", data=data).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360a4c4",
   "metadata": {},
   "source": [
    "# Week 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73375ad",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291688f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  value   R-squared:                       0.865\n",
      "Model:                            OLS   Adj. R-squared:                  0.860\n",
      "Method:                 Least Squares   F-statistic:                     162.1\n",
      "Date:                Thu, 20 Nov 2025   Prob (F-statistic):           6.10e-33\n",
      "Time:                        11:56:13   Log-Likelihood:                -179.30\n",
      "No. Observations:                  80   AIC:                             366.6\n",
      "Df Residuals:                      76   BIC:                             376.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              8.6411      0.522     16.552      0.000       7.601       9.681\n",
      "treated               -2.0319      0.738     -2.752      0.007      -3.502      -0.561\n",
      "post_event             3.3985      0.738      4.603      0.000       1.928       4.869\n",
      "treated:post_event    11.6063      1.044     11.116      0.000       9.527      13.686\n",
      "==============================================================================\n",
      "Omnibus:                        0.992   Durbin-Watson:                   0.856\n",
      "Prob(Omnibus):                  0.609   Jarque-Bera (JB):                0.927\n",
      "Skew:                           0.035   Prob(JB):                        0.629\n",
      "Kurtosis:                       2.477   Cond. No.                         6.85\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Time axis\n",
    "time_points = np.arange(0, 40)\n",
    "\n",
    "# Event happens here\n",
    "event_time = 20\n",
    "true_jump = 5\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Create two groups: treatment and control\n",
    "# Treatment has stable upward trend\n",
    "# Control has flattening trend before event, which violates parallel trends\n",
    "\n",
    "for t in time_points:\n",
    "    # Treatment group\n",
    "    treatment_trend = 2 + 0.5 * t\n",
    "    treatment_jump = true_jump if t >= event_time else 0\n",
    "    treatment_value = treatment_trend + treatment_jump + np.random.normal(0, 0.8)\n",
    "    rows.append([\"treat\", t, treatment_value, int(t >= event_time), 1])\n",
    "\n",
    "    # Control group\n",
    "    if t < 10:\n",
    "        control_trend = 5 + 0.5 * t\n",
    "    else:\n",
    "        control_trend = 5 + 0.5 * 10 + 0.1 * (t - 10)\n",
    "\n",
    "    control_value = control_trend + np.random.normal(0, 0.8)\n",
    "    rows.append([\"control\", t, control_value, int(t >= event_time), 0])\n",
    "\n",
    "data = pd.DataFrame(rows, columns=[\"group\", \"time\", \"value\", \"post_event\", \"treated\"])\n",
    "\n",
    "# Differences-in-differences model\n",
    "model = smf.ols(\"value ~ treated * post_event\", data=data).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
