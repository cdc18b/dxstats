In all cases, written answers (apart from code) should not be longer than about three paragraphs.  Graders may not read all of your
submission if it is longer than that.

Homework reflection 1

1. In Coding Quiz 1, you are asked to find the distance of the farthest match in a set.  Is this farthest match distance too far to be a meaningful match?  How can you decide this?

The max distance of approximately 0.21 is likely too far to be meaningful. I decided this by plotting a histogram of the Z values, calculating the standard deviation, and plotting a histrogram of the distances.
For the Z value distribution, it appears to have a mean around 0.5 with a standard deviation of approximately 0.3. This tells me that while the farthest distance is within one standard deviation of the Z values, it is closer to the higher end.
Next, I plotted a histogram of the distances. I discovered that the mean was approximately 0.05 and the standard deviation was 0.07. This is approximately 3 standard deviations away. Additionally, the 95th percentile is approximately 0.20.

2. In Coding Quiz 1, there are two approaches to matching: 
(A) Picking the best match X = 0 corresponding to each X = 1 using Z values.
(B) Using radius_neighbors to pick all matches X = 0 within a distance of 0.2 of each X = 1.

Invent your own type of matching similar to 1 and 2 (or look one up on the internet), which has a different way to pick the matches in X = 0.  Clearly explain the approach you invented or found.

I created a method I call weighted matching. Instead of picking only one match or only the matches in a radius, I use all controls (X=0) and I gave them a weight based on how close they are to Z
in the treated unit. If Z is an exact match, the weight is 1. If Z is far away, the weight approaches 0. So every control is included, but the closer controls matter more in determining the effect.
This means that information is not lost, but that controls that are closer are prioritized. The weight is calculated by doing 1 - (distances / max_distance), with a clipping used to stay between 0 and 1.
Doing this on the quiz 1 homeowrk 1.2 data, I found an effect of approximately 0.69, which was higher than the effects found using nearest neighbor or the radius neighbors.

Homework reflection 2

1. Invent an example situation that would use fixed effects.

An example of when to use fixed effects is estimating the impact of the same gun control policy, like an assault weapons ban, across three countries over several years. We assume each country has traits that do not change over time and that affect the baseline level of gun deaths, like legal traditions, culture, geography, economy, and demographics.
With country fixed effects, we control for those baselines. This lets us isolate the policy’s effect. For example, we might estimate that the ban reduces gun deaths by 5 per 100,000 people per year on average, plus random noise with mean 0. Countries can start at different baseline levels,
but the policy effect is the same for all countries in this fixed effects model.

2. Write a Python program that performs a bootstrap simulation to find the variance in the mean of the Pareto distribution when different samples are taken.  Explain what you had to do for this.  As you make the full sample size bigger (for the same distribution), what happens to the variance of the mean of the samples?  Does it stay about the same, get smaller, or get bigger?

I set the shape to 2.5 and the minimum to 1 so the data is still heavy-tailed but has a real variance. For each sample size, I made one dataset. Then I did a bootstrap: I made many new “fake” samples by picking numbers from my dataset at random with replacement, which means I could pick the same number more than once. I found the average of each fake sample and looked at how
spread out those averages were. That spread is my estimate of the variance of the sample mean for that sample size. I set a random seed so someone else can repeat my steps and get the same results. When I compared different sample sizes, I saw that as the sample size got bigger, the variance of the mean got smaller. Bigger samples make the average steadier and
less fluctuating, which is what I expect when you average more numbers.

Homework reflection 3

1. In the event study in Coding Quiz 3, how would we go about testing for a change in the second derivative as well?

2. Create your own scenario that illustrates differences-in-differences. Describe the story behind the data and show whether there is a nonzero treatment effect.

Homework reflection 4

1. The Coding Quiz gives two options for instrumental variables.  For the second item (dividing the range of W into multiple ranges), explain how you did it, show your code, and discuss any issues you encountered.

2. Plot the college outcome (Y) vs. the test score (X) in a small range of test scores around 80. On the plot, compare it with the Y probability predicted by logistic regression. The ground truth Y value is 0 or 1; don't just plot 0 or 1 - that will make it unreadable.  Find some way to make it look better than that.
